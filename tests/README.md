# Semiosis Tests

This directory contains the test suite for the Semiosis framework.

## Test Organization

```
tests/
â”œâ”€â”€ agents/                    # Agent implementation tests
â”‚   â”œâ”€â”€ test_ollama_agent.py   # Local Ollama model tests
â”‚   â”œâ”€â”€ test_together_agent.py # Together AI hosted model tests
â”‚   â””â”€â”€ test_agent_factory.py  # Agent factory integration tests
â”œâ”€â”€ unit/                      # Unit tests for individual components
â”œâ”€â”€ integration/               # Integration tests between components
â””â”€â”€ run_tests.py               # Test runner script
```

## Running Tests

### Run All Tests
```bash
cd tests
python3 run_tests.py
```

### Run Specific Test Files
```bash
# Test Ollama agent (requires Ollama running locally)
python3 tests/agents/test_ollama_agent.py

# Test Together AI agent (requires TOGETHER_API_KEY)
python3 tests/agents/test_together_agent.py

# Test agent factory
python3 tests/agents/test_agent_factory.py
```

## Prerequisites

### Required Python Packages
```bash
pip install requests openai
```

### API Keys and Services

**Together AI Tests:**
- Set environment variable: `export TOGETHER_API_KEY=your_key_here`
- Get your key at: https://api.together.xyz

**Ollama Tests:**
- Install Ollama: `curl -fsSL https://ollama.ai/install.sh | sh`
- Start service: `ollama serve`
- Pull a model: `ollama pull sqlcoder:7b`

## Test Categories

### Agent Tests (`tests/agents/`)
- **Unit tests** for individual agent implementations
- **Integration tests** for agent factory and configuration
- **Live API tests** (when credentials available)

### Expected Test Coverage
- Agent creation and configuration validation
- Factory pattern integration 
- Error handling and edge cases
- Cost calculation accuracy
- Logprobs extraction (where supported)
- Model availability and validation

### CI/CD Integration
Tests are designed to:
- Skip live API tests when credentials unavailable
- Provide clear success/failure feedback
- Run quickly for development workflow
- Support both local and CI environments

## Adding New Tests

### For New Agent Types
1. Create `test_<agent_name>_agent.py` in `tests/agents/`
2. Follow the pattern from existing agent tests
3. Add factory integration tests
4. Update this README

### For New Components
1. Create appropriate subdirectory (`unit/`, `integration/`)
2. Follow naming convention: `test_<component>.py`
3. Add to test runner if needed

## Test Output

The test runner provides:
- âœ“ Prerequisites check (packages, API keys, services)
- âœ“ Individual test file results
- âœ“ Comprehensive summary
- âš  Clear guidance for missing dependencies
- ðŸŽ‰ Celebration for full success

Example output:
```
=== Checking Prerequisites ===
âœ“ requests installed
âœ“ openai installed
âœ“ TOGETHER_API_KEY: Set
âš  Ollama service: Not running

=== Running test_together_agent.py ===
âœ“ test_together_agent.py passed

=== Test Summary ===
âœ“ test_together_agent.py
âš  test_ollama_agent.py

Results: 1/2 tests passed
```